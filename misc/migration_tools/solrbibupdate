#!/usr/bin/env perl

use Koha;
use C4::Context;
use C4::Items qw(GetMarcWithItems);
use WebService::Solr;
use Koha::Solr::IndexStrategy::MARC;
use Koha::Solr::Document::MARC;
use Koha::Changelog::DBLog;
use File::Slurp;
use DateTime;
use Try::Tiny;
use Getopt::Long qw(GetOptions);
use Log::Dispatch;
use Log::Dispatch::Screen;
use Carp;
use Parallel::ForkManager;
use Time::HiRes qw(gettimeofday);
use List::MoreUtils qw(natatime);

our $log = Log::Dispatch->new();

my ($all, $timestamp, $to_stdout, $workers) = (undef, undef, undef, 1);
my $optcheck = GetOptions(
    'a|all' => \$all,
    's|since:s' => \$timestamp,
    'w|workers:i' => \$workers,
    'o' => \$to_stdout,
    'v|verbose' => sub {
        $log->add( Log::Dispatch::Screen->new(
                       min_level=>'info', newline=>1, stderr=>1))
    },
    );

my $solr = WebService::Solr->new( C4::Context->config('solr')->{url} );
$timestamp //= get_timestamp($solr);

my $todos;
if ( $all ) {
    $log->info('Collecting all bibs');
    my $bibnums = C4::Context->dbh->selectcol_arrayref(
        'SELECT biblionumber FROM biblio');
    my $now = DateTime->now->ymd . ' ' . DateTime->now->hms;
    $todos = [ map { {id=>$_, action=>'update', stamp=>$now} } @{$bibnums} ];
}
else {
    $log->info("Collecting bibs updated since $timestamp");
    $todos = Koha::Changelog::DBLog
        ->new( rtype => 'biblio' )
        ->get_todos( $timestamp );
}

$log->info('Processing '.@$todos.' bibs');

my $forker = Parallel::ForkManager->new($workers);
my $todoitr = natatime scalar @$todos / $workers, @$todos;
my $youngest_ts;# = process_list($solr, $todos);
while (my @todo_part = $todoitr->()) {
    next if $forker->start;
    $youngest_ts = process_list($solr, \@todo_part);
    $forker->finish;
}
$forker->wait_all_children;

update_timestamp($solr, $youngest_ts);

exit;


sub s2hms {
    my $s = shift;
    my $hms;
    if ($s > 5400) {
        $hms = sprintf '%.02fh', $s / 3600;
    }
    elsif ($s > 120) {
        $hms = sprintf '%.02fm', $s / 60;
    }
    else {
        $hms = sprintf '%.02fs', $s;
    }
    return $hms;
}

sub process_list {
    my ($solr, $todos) = @_;
    return unless @$todos;

    my $youngest_ts = $todos->[$#$todos]->{stamp};
    $youngest_ts =~ s/ /T/;
    $youngest_ts .= '.000Z';

    my %deletes = map { $_->{id} => 1} grep { $_->{action} ~~ 'delete' } @$todos;
    my %updates = map { $_->{id} => 1} grep { $_->{action} ~~ 'update' } @$todos;

    # Remove deleted items from updates list
    %updates = map { $_ => 1 } grep { ! exists $deletes{$_} } keys %updates;

    my @delete_ids = map { 'bib_'.$_} keys %deletes;
    $log->info('Deleting '. @delete_ids .' docs');
    $solr->delete( {id => \@delete_ids} );

    my $rules_text = read_file( C4::Context->config('solr')->{biblio_rules} );
    my $r = Koha::Solr::IndexStrategy::MARC->new( rules_text => $rules_text );
    my @update_docs;
    my ($update_count, $render_errors, $update_errors) = (0, 0, 0);
    my $batch_size = 500;
    my $queue_size = scalar keys %updates;
    my ($start_time, undef) = gettimeofday();
    my $recent_time = $start_time;

    my $doc_with_catch = sub {
        my $bibnum = shift;
        my $record = GetMarcWithItems($bibnum);
        return unless $record;
        my $doc = try {
            Koha::Solr::Document::MARC->new(
                record => $record, strategy => $r );
        }
        catch {
            carp "Error rendering $bibnum into Solr doc: $_";
            $render_errors++;
            undef;
        };
        return $doc;
    };

    my $add_with_catch = sub {
        my ($now, undef) = gettimeofday();
        my $total_elapsed_seconds = ($now - $start_time) || 1;
        my $dps_all = int($update_count / $total_elapsed_seconds);
        my $docs_remaining = $queue_size - $update_count;
        my $est_seconds_remaining = int($docs_remaining / $dps_all);

        my $elapsed = s2hms($total_elapsed_seconds);
        my $remaining = s2hms($est_seconds_remaining);
        my $msg =
            sprintf q{completed %d/%d, %d d/s, %s elapsed, %s remaining},
            $update_count, $queue_size, $dps_all, $elapsed, $remaining;
        my $recent_time = $now;

        $log->info($msg);

        try {
            $solr->add( \@update_docs );
        }
        catch {
            carp "Error uploading batch into Solr: $_";
            $update_errors++;
            undef;
        };
        $solr->commit;
        @update_docs = ();
    };

    for ( keys %updates ) {
        my $doc = $doc_with_catch->($_);
        next unless $doc;
        $update_count++;
        say $doc if $to_stdout;
        push @update_docs, $doc;
        $add_with_catch->() if (@update_docs >= $batch_size);
    }
    $add_with_catch->();

    $log->info("Updated $update_count records with $render_errors render errors and $update_errors update errors.");

    return $youngest_ts;
}

sub update_timestamp {
    my ($solr, $youngest_ts) = @_;
    $log->info('Updated timestamp is '.($youngest_ts ? $youngest_ts : '(undef)'));
    return unless $youngest_ts;

    my $metadoc = WebService::Solr::Document->new(
        id => 'bibupdate', rtype => 'meta',
        timestamp => $youngest_ts );
    $solr->update($metadoc);
    return;
}

sub get_timestamp {
    my $solr = shift;

    my $tsres = $solr->search(
        'rtype:meta AND id:bibupdate', {qt => 'advanced', fl => 'timestamp,id'});
    croak 'Failure to query Solr service' unless $tsres->ok;

    my $response = $tsres->content->{response};
    my $metadoc;
    if ($response->{numFound} == 0) {
        # No meta document found, so create one.
        $metadoc = WebService::Solr::Document->new(
            id => 'bibupdate', rtype => 'meta',
            timestamp => '1970-01-01T00:00:00.000Z' );
    }
    else {
        ($metadoc) = $tsres->docs;
    }
    return $metadoc->value_for('timestamp');
}
