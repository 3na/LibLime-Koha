#!/usr/bin/env perl

use Koha;
use C4::Context;
use C4::Items qw(GetMarcWithItems);
use WebService::Solr;
use Koha::Solr::IndexStrategy::MARC;
use Koha::Solr::Document::MARC;
use Koha::Changelog::DBLog;
use File::Slurp;
use DateTime;
use Try::Tiny;
use Getopt::Long qw(GetOptions);
use Log::Dispatch;
use Log::Dispatch::Screen;
use Carp;
use Parallel::ForkManager;
use Time::HiRes qw(gettimeofday);
use List::MoreUtils qw(natatime);
use POSIX qw();

my $log = Log::Dispatch->new();

my ($all, $timestamp, $to_stdout, $workers) = (undef, undef, undef, 1);
my $optcheck = GetOptions(
    'a|all' => \$all,
    's|since:s' => \$timestamp,
    'w|workers:i' => \$workers,
    'o' => \$to_stdout,
    'v|verbose' => sub {
        $log->add( Log::Dispatch::Screen->new(
                       min_level=>'info', newline=>1, stderr=>1))
    },
    );

$SIG{HUP} = $SIG{TERM} = $SIG{INT} = $SIG{QUIT} = sub {
    $log->warn('Caught signal. Exiting.');
    my $todos = [ {stamp => C4::Context->preference('SolrBibUpdateTS')} ];
    update_timestamp( $todos );
    exit 1;
};

my $solr = WebService::Solr->new( C4::Context->config('solr')->{url},
    { autocommit => 0 } );

my $todos;
if ( $all ) {
    $log->info('Collecting all bibs');
    my $bibnums = C4::Context->dbh->selectcol_arrayref(
        'SELECT biblionumber FROM biblio');
    $timestamp = DateTime->now->ymd . ' ' . DateTime->now->hms;
    $todos =
        [ map { {id=>$_, action=>'update', stamp=>$timestamp} } @{$bibnums} ];
}
else {
    $timestamp //= get_timestamp();
    $log->info("Collecting bibs updated since $timestamp");
    $todos = Koha::Changelog::DBLog
        ->new( rtype => 'biblio' )
        ->get_todos( $timestamp );
}

update_timestamp($todos);

$log->info('Processing '.@$todos.' changelog entries');
my $forker = Parallel::ForkManager->new($workers);
my $todoitr = natatime(@$todos / $workers, @$todos);
while (my @todo_part = $todoitr->()) {
    next if $forker->start;
    $SIG{HUP} = $SIG{TERM} = $SIG{INT} = $SIG{QUIT} = undef;
    process_list($solr, \@todo_part);
    $forker->finish;
}
$forker->wait_all_children;

exit;


sub s2hms {
    my $s = shift;
    my $hms;
    if ($s > 5400) {
        $hms = sprintf '%.02fh', $s / 3600;
    }
    elsif ($s > 120) {
        $hms = sprintf '%.02fm', $s / 60;
    }
    else {
        $hms = sprintf '%.02fs', $s;
    }
    return $hms;
}

sub process_list {
    my ($solr, $todos) = @_;
    return unless @$todos;

    my %deletes = map { $_->{id} => 1} grep { $_->{action} ~~ 'delete' } @$todos;
    my %updates = map { $_->{id} => 1} grep { $_->{action} ~~ 'update' } @$todos;

    # Remove deleted items from updates list
    %updates = map { $_ => 1 } grep { ! exists $deletes{$_} } keys %updates;

    my @delete_ids = map { 'bib_'.$_} keys %deletes;
    $log->info('Deleting '. @delete_ids .' docs');
    $solr->delete( {id => \@delete_ids} ) if @delete_ids;
    $log->info('Delete complete');

    my $rules_text = read_file( C4::Context->config('solr')->{biblio_rules} );
    my $r = Koha::Solr::IndexStrategy::MARC->new( rules_text => $rules_text );
    my @update_docs;
    my ($update_count, $render_errors, $update_errors) = (0, 0, 0);
    my $batch_size = 500;
    my $queue_size = scalar keys %updates;
    my ($start_time, undef) = gettimeofday();
    my $recent_time = $start_time;

    $log->info("Have $queue_size bibs in queue");

    my $doc_with_catch = sub {
        my $bibnum = shift;
        $log->info("Expressing $bibnum");
        my $record = GetMarcWithItems($bibnum);
        return unless $record;
        my $doc = try {
            $update_count++;
            Koha::Solr::Document::MARC->new(
                record => $record, strategy => $r );
        }
        catch {
            carp "Error rendering $bibnum into Solr doc: $_";
            $render_errors++;
            $update_count--;
            undef;
        };
        return $doc;
    };

    my $add_with_catch = sub {
        my ($now, undef) = gettimeofday();
        my $total_elapsed_seconds = ($now - $start_time) || 1;
        my $dps_all = int($update_count / $total_elapsed_seconds);
        my $docs_remaining = $queue_size - $update_count;
        my $est_seconds_remaining = int($docs_remaining / $dps_all);

        my $elapsed = s2hms($total_elapsed_seconds);
        my $remaining = s2hms($est_seconds_remaining);
        my $msg =
            sprintf q{completed %d/%d, %d d/s, %s elapsed, %s remaining},
            $update_count, $queue_size, $dps_all, $elapsed, $remaining;
        my $recent_time = $now;

        $log->info($msg);

        try {
            $solr->add( \@update_docs );
        }
        catch {
            carp "Error uploading batch into Solr: $_";
            $update_errors++;
            undef;
        };
        @update_docs = ();
        $log->info('Batch complete');
    };

    for ( keys %updates ) {
        my $doc = $doc_with_catch->($_);
        next unless $doc;
        say $doc if $to_stdout;
        push @update_docs, $doc;
        $add_with_catch->() if (@update_docs >= $batch_size);
    }
    $add_with_catch->();

    $log->info("Updated $update_count records with $render_errors render errors and $update_errors update errors.");
    return;
}

sub get_timestamp {
    return C4::Context->preference('SolrBibUpdateTS')
        // '1970-01-01 00:00:00';
}

sub update_timestamp {
    my $todos = shift;
    return unless @$todos;

    $todos = [ sort { $a->{stamp} cmp $b->{stamp} } @$todos ];
    my $youngest_entry = pop @$todos;
    my $youngest_ts = $youngest_entry->{stamp};

    $log->info('Updated timestamp is '.($youngest_ts ? $youngest_ts : '(undef)'));
    return unless $youngest_ts;

    C4::Context->preference_set('SolrBibUpdateTS', $youngest_ts);
    return;
}
